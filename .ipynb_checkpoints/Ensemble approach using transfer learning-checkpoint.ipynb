{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf8df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import EfficientNetB7,EfficientNetB6, DenseNet201, InceptionV3, ResNet101\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the paths to your training and validation data\n",
    "train_data_dir = 'NLM Augmentation/train'\n",
    "validation_data_dir = 'NLM Augmentation/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3c8319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6951 images belonging to 7 classes.\n",
      "Found 3001 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set the image size and batch size\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 16\n",
    "\n",
    "# Data augmentation for the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Only rescale for validation data (no data augmentation)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Load and augment the training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load and rescale the validation data\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada16a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n",
      "165234480/165234480 [==============================] - 29s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171446536/171446536 [==============================] - 30s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Define the number of classes in your dataset\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Function to create individual transfer learning models\n",
    "def create_transfer_learning_model(base_model, img_width, img_height):\n",
    "    # Load the base model (without the top classification layers)\n",
    "    base_model = base_model(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "    \n",
    "    # Freeze the pre-trained layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Add a new classification head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Create the transfer learning model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create individual models using transfer learning\n",
    "efficientnet_b6_model = create_transfer_learning_model(EfficientNetB6, img_width, img_height)\n",
    "densenet_model = create_transfer_learning_model(DenseNet201, img_width, img_height)\n",
    "inception_model = create_transfer_learning_model(InceptionV3, img_width, img_height)\n",
    "resnet101_model = create_transfer_learning_model(ResNet101, img_width, img_height)\n",
    "efficientnet_b7_model = create_transfer_learning_model(EfficientNetB7, img_width, img_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dcb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of training and validation samples\n",
    "num_train_samples = len(train_generator.filenames)\n",
    "num_val_samples = len(validation_generator.filenames)\n",
    "\n",
    "# Set the number of training epochs\n",
    "epochs = 10\n",
    "\n",
    "# Train individual models\n",
    "efficientnet_b6_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_val_samples // batch_size\n",
    ")\n",
    "# Save the model\n",
    "efficientnet_b6_model.save('efficientnet_b6_model')\n",
    "\n",
    "densenet_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_val_samples // batch_size\n",
    ")\n",
    "# Save the model\n",
    "densenet_model.save('densenet_model')\n",
    "\n",
    "inception_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_val_samples // batch_size\n",
    ")\n",
    "# Save the model\n",
    "inception_model.save('inception_model')\n",
    "\n",
    "resnet101_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_val_samples // batch_size\n",
    ")\n",
    "# Save the model\n",
    "resnet101_model.save('resnet101_model')\n",
    "\n",
    "efficientnet_b7_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_val_samples // batch_size\n",
    ")\n",
    "# Save the model\n",
    "efficientnet_b7_model.save('efficientnet_b7_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform ensemble prediction using majority voting\n",
    "def ensemble_prediction(models, data_generator):\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        preds = model.predict(data_generator, verbose=1)\n",
    "        predictions.append(preds)\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "# Prepare the ensemble of models\n",
    "ensemble_models = [efficientnet_b6_model, densenet_model, inception_model, resnet101_model, efficientnet_b7_model]\n",
    "\n",
    "# Perform ensemble prediction on the validation data\n",
    "ensemble_validation_predictions = ensemble_prediction(ensemble_models, validation_generator)\n",
    "\n",
    "# Evaluate the ensemble performance\n",
    "ensemble_validation_loss, ensemble_validation_accuracy = ensemble_models[0].evaluate(validation_generator)\n",
    "print(\"Ensemble Validation Accuracy:\", ensemble_validation_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
